{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "B_MLP_MNIST_Dataset.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHDQXZy967Hv"
      },
      "source": [
        "<a href=\"https://www.bigdatauniversity.com\"><img src=\"https://ibm.box.com/shared/static/qo20b88v1hbjztubt06609ovs85q8fau.png\" width=\"400px\"  align=\"center\"></a>\n",
        "<h1 align=\"center\"><font size=\"5\">CONVOLUTIONAL NEURAL NETWORK APPLICATION</font></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHjr6QhTTwxE"
      },
      "source": [
        "Lets create a simple Multi-layer perceptron, a simple type of Neural Network, to perform classification tasks on the MNIST digits dataset. MNIST dataset reference: <a href=\"http://yann.lecun.com/exdb/mnist/\">click here</a> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go0rBXvGYCfy",
        "outputId": "bc8513ad-751a-410b-bb40-1ce1a674fd4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        }
      },
      "source": [
        "!pip install tensorflow==1.8.0"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/c6/d08f7c549330c2acc1b18b5c1f0f8d9d2af92f54d56861f331f372731671/tensorflow-1.8.0-cp36-cp36m-manylinux1_x86_64.whl (49.1MB)\n",
            "\u001b[K     |████████████████████████████████| 49.1MB 87kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (1.33.2)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (0.10.0)\n",
            "Collecting tensorboard<1.9.0,>=1.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/a6/0ae6092b7542cfedba6b2a1c9b8dceaf278238c39484f3ba03b03f07803c/tensorboard-1.8.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 44.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (1.18.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (0.35.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0) (3.3.3)\n",
            "Collecting bleach==1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0) (1.0.1)\n",
            "Collecting html5lib==0.9999999\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 41.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow==1.8.0) (50.3.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0) (3.4.0)\n",
            "Building wheels for collected packages: html5lib\n",
            "  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html5lib: filename=html5lib-0.9999999-cp36-none-any.whl size=107220 sha256=4ed1b272018d5cfb6baab354ab84bd3215681a44f0dd401960c309353846e9d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "Successfully built html5lib\n",
            "Installing collected packages: html5lib, bleach, tensorboard, tensorflow\n",
            "  Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Found existing installation: bleach 3.2.1\n",
            "    Uninstalling bleach-3.2.1:\n",
            "      Successfully uninstalled bleach-3.2.1\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed bleach-1.5.0 html5lib-0.9999999 tensorboard-1.8.0 tensorflow-1.8.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fmb-0jvGYYJz",
        "outputId": "fea5e184-5412-4737-acea-82d7d0394b01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.8.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjAlIflj7yH7",
        "outputId": "44dac46b-1d68-4453-85cc-9401ab19c568",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-8bf8ae5a5303>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40w78y-o-IUR"
      },
      "source": [
        "We will use the interactive session that is more suitable for environments like Jupyter notebooks for coding and running on the fly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Worq40cZ-j3E"
      },
      "source": [
        "sess = tf.InteractiveSession()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b9qN-r4-qgM"
      },
      "source": [
        "Create Placeholders:\n",
        "It is a best practice to create placeholders before variable assignments when using TensorFlow. Here we'll create placeholders for inputs (\"Xs\") and outputs (\"Ys\").   \n",
        "\n",
        "<b>Placeholder 'X':</b> represents the \"space\" allocated input or the images. \n",
        "<ul>\n",
        "    <li>Each input has 784 pixels distributed by a 28 width x 28 height matrix</li>   \n",
        "    <li>The 'shape' argument defines the tensor size by its dimensions.</li>     \n",
        "    <li>1st dimension = None. Indicates that the batch size, can be of any size.</li>     \n",
        "    <li>2nd dimension = 784. Indicates the number of pixels on a single flattened MNIST image.</li>    \n",
        "</ul>\n",
        "    \n",
        "<b>Placeholder 'Y':</b> Represents the final output or the labels.\n",
        "<ul>\n",
        "    <li>10 possible classes (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)</li>  \n",
        "    <li>The 'shape' argument defines the tensor size by its dimensions.</li>    \n",
        "    <li>1st dimension = None. Indicates that the batch size, can be of any size.</li>     \n",
        "    <li>2nd dimension = 10. Indicates the number of targets/outcomes</li>   \n",
        "</ul>\n",
        "<b>dtype for both placeholders:</b> if we are not sure, we use tf.float32. The limitation here is that the later presented softmax function only accepts float32 or float64 dtypes. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skXPIk_T_GIj"
      },
      "source": [
        "x  = tf.placeholder(tf.float32, shape=[None, 784])\n",
        "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cYiH87xOZhF"
      },
      "source": [
        "Create weights and biases, for this purpose they will be used as arrays filled with zeros. The values that we choose here can be critical."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXJxotb2OnhC"
      },
      "source": [
        "# Weight tensor\n",
        "W = tf.Variable(tf.zeros([784, 10],tf.float32))\n",
        "# Bias tensor\n",
        "b = tf.Variable(tf.zeros([10],tf.float32))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auzKbrkjO2eG"
      },
      "source": [
        "# run the op initialize_all_variables using an interactive session\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2xFR3ghQesZ"
      },
      "source": [
        "\n",
        "<h3>Adding Weights and Biases to input</h3>\n",
        "\n",
        "<img src=\"https://ibm.box.com/shared/static/88ksiymk1xkb10rgk0jwr3jw814jbfxo.png\" alt=\"HTML5 Icon\" style=\"width:400px;height:350px;\"> \n",
        "<div style=\"text-align:center\">Illustration showing how weights and biases are added to neurons/nodes. </div>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGfWpW1rQkcx",
        "outputId": "b82464ef-651f-46ed-9694-6f04ea3ac4c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# mathematical operation to add weights and biases to the inputs\n",
        "tf.matmul(x,W) + b"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'add:0' shape=(?, 10) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stDx2-kLQvMu"
      },
      "source": [
        "<h3>Softmax Regression</h3>\n",
        "\n",
        "Softmax is an activation function that is normally used in classification problems. It generate the probabilities for the output. For example, our model will not be 100% sure that one digit is the number nine, instead, the answer will be a distribution of probabilities where, if the model is right, the nine number will have a larger probability than the other other digits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoBpPGb9Q5Oe"
      },
      "source": [
        "y = tf.nn.softmax(tf.matmul(x,W) + b)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk5tMi8JQ9Sx"
      },
      "source": [
        "Logistic function output is used for the classification between two target classes 0/1. Softmax function is generalized type of logistic function. That is, Softmax can output a multiclass categorical probability distribution. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zix-LfxoRBz_"
      },
      "source": [
        "# # Cost function\n",
        "\n",
        "It is a function that is used to minimize the difference between the right answers (labels) and estimated outputs by our Network. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9r7bjnDRLZW"
      },
      "source": [
        "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHQyB4SgRSgk"
      },
      "source": [
        "# Type of optimization: Gradient Descent\n",
        "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duMeaUswRoYc"
      },
      "source": [
        "Train using minibatch Gradient Descent.\n",
        "\n",
        "In practice, Batch Gradient Descent is not often used because is too computationally expensive. The good part about this method is that you have the true gradient, but with the expensive computing task of using the whole dataset in one time. Due to this problem, Neural Networks usually use minibatch to train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEbOF9xWRpPN"
      },
      "source": [
        "#Load 50 training examples for each training iteration   \n",
        "for i in range(1000):\n",
        "    batch = mnist.train.next_batch(50)\n",
        "    train_step.run(feed_dict={x: batch[0], y_: batch[1]})"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8B4bvy66Rzei"
      },
      "source": [
        "<h3>Testing the model</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP1O2mXAR4Sc",
        "outputId": "02d3ec95-e462-46a1-9f16-e3b078c1a93e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "acc = accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}) * 100\n",
        "print(\"The final accuracy for the simple ANN model is: {} % \".format(acc) )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The final accuracy for the simple ANN model is: 91.82000160217285 % \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wb9CrrzFR9Pz"
      },
      "source": [
        "sess.close() #finish the session"
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}